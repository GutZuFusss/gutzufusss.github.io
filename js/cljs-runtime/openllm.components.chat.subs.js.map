{"version":3,"sources":["openllm/components/chat/subs.cljs"],"mappings":";AAKA,2DAAA,uLAAA,gDAAA,mFAAA,rXAACA,qeAGA,WAAKC,QAAQC;AAAb,AACE,OAAA,0GAAmBD;;AAEtB,2DAAA,+KAAA,gDAAA,mFAAA,7WAACD,6dAGA,WAAKC,QAAQC;AAAb,AACE,OAAA,kGAAeD;;AAElB,2DAAA,4KAAA,gDAAA,mFAAA,1WAACD,0dAGA,WAAKC,QAAQC;AAAb,AACE,OAAA,+GAAqBD;;AAKxB,2DAAA,iLAAA,gDAAA,mFAAA,/WAACD,+dAGA,WAAKC,QAAQC;AAAb,AACE,OAAA,qGAAgBD;;AAQnB,2DAAA,kKAAA,gDAAA,mFAAA,uIAAA,gDAAA,mFAAA,6IAAA,gDAAA,mFAAA,13BAACD,+/BAKA,WAAAG,SAAmDD;AAAnD,AAAA,IAAAE,aAAAD;oBAAA,AAAAE,4CAAAD,WAAA,IAAA,3EAAME;uBAAN,AAAAD,4CAAAD,WAAA,IAAA,9EAAoBG;mBAApB,AAAAF,4CAAAD,WAAA,IAAA,1EAAqCI;AAArC,AACE,IAAMC,eAAa,AAACC,qCAA0BF;AAA9C,AACE,mEAAA,kBAAA,KAAA,uEAAA,KAAA,lHAAKF,oBACAG,uEACSF","names":["re_frame.core.reg_sub","chat-db","_","p__39168","vec__39169","cljs.core.nth","prompt-layout","chat-input-value","chat-history","conversation","openllm.util/chat-history->string"],"sourcesContent":["(ns openllm.components.chat.subs\n  (:require [openllm.components.subs :as components-subs]\n            [openllm.util :as util]\n            [re-frame.core :refer [reg-sub]]))\n\n(reg-sub\n ::chat-input-value\n :<- [::components-subs/chat-db]\n (fn [chat-db _]\n   (:chat-input-value chat-db)))\n\n(reg-sub\n ::chat-history\n :<- [::components-subs/chat-db]\n (fn [chat-db _]\n   (:chat-history chat-db)))\n\n(reg-sub\n ::modal-open?\n :<- [::components-subs/chat-db]\n (fn [chat-db _]\n   (:layout-modal-open? chat-db)))\n\n;; This subscription informs it's subscribers about the current prompt layout and\n;; possible changes. The user can freely choose any prompt layout, right now it\n;; only acts as some kind of preamble.\n(reg-sub\n ::prompt-layout\n :<- [::components-subs/chat-db]\n (fn [chat-db _]\n   (:prompt-layout chat-db)))\n\n;; This subscription materializes all the data neccessary to build a prompt for a\n;; chat model.\n;; In essence, it is a concatenation of the prompt layout, the chat history, and\n;; the current input value. Lastly we indicate to the model, that it should keep\n;; generating tokens from the AI persona.\n;; TODO: The names should probably be configurable by the user in the future.\n(reg-sub\n ::prompt\n :<- [::prompt-layout]\n :<- [::chat-input-value]\n :<- [::chat-history]\n (fn [[prompt-layout chat-input-value chat-history] _]\n   (let [conversation (util/chat-history->string chat-history)]\n     (str prompt-layout \"\\n\"\n          conversation \"\\n\"\n          \"user: \" chat-input-value \"\\n\"\n          \"model: \"))))\n"]}